#!/usr/bin/env tsx

/**
 * Thu·∫≠t to√°n t·ª± ƒë·ªông generate exports trong package.json t·ª´ th∆∞ m·ª•c dist
 * 
 * Usage:
 *   tsx scripts/generate-exports.ts [package-path]
 * 
 * Examples:
 *   tsx scripts/generate-exports.ts packages/image-loader
 *   tsx scripts/generate-exports.ts packages/ui
 *   tsx scripts/generate-exports.ts  (uses current directory)
 * 
 * ALGORITHM:
 * ==========
 * 
 * 1. SCAN TH·ª® M·ª§C DIST
 *    - ƒê·ªçc c·∫•u tr√∫c th∆∞ m·ª•c dist/ (recursively)
 *    - L·ªçc c√°c file c√≥ extension: .js, .cjs, .d.ts
 *    - B·ªè qua c√°c file kh√¥ng ph·∫£i l√† entry points
 * 
 * 2. PH√ÇN LO·∫†I FILES
 *    - Nh√≥m files theo base name (b·ªè extension)
 *    - M·ªói module c·∫ßn c√≥ 3 files: .js, .cjs, .d.ts
 *    - V√≠ d·ª•: index.js, index.cjs, index.d.ts ‚Üí module "index"
 * 
 * 3. T·∫†O EXPORT PATHS
 *    - Root entry (index): "." ‚Üí "./dist/index.*"
 *    - Subpath entries: "./{relative-path}" ‚Üí "./dist/{relative-path}.*"
 *    - Lo·∫°i b·ªè "dist/" prefix trong export path
 *    - Convert file path th√†nh export path:
 *      * dist/index.* ‚Üí "."
 *      * dist/loaders/cloudinary.* ‚Üí "./loaders/cloudinary"
 *      * dist/core/types.* ‚Üí "./core/types"
 * 
 * 4. VALIDATE MODULES
 *    - Ch·ªâ t·∫°o export n·∫øu module c√≥ ƒë·ªß 3 files (.js, .cjs, .d.ts)
 *    - Ho·∫∑c √≠t nh·∫•t c√≥ .js v√† .d.ts (cho ESM-only)
 *    - B·ªè qua c√°c file kh√¥ng ƒë·ªß ƒëi·ªÅu ki·ªán
 * 
 * 5. GENERATE EXPORTS OBJECT
 *    - T·∫°o object v·ªõi structure:
 *      {
 *        "{export-path}": {
 *          "types": "./dist/{path}.d.ts",
 *          "import": "./dist/{path}.js",
 *          "require": "./dist/{path}.cjs"
 *        }
 *      }
 *    - S·∫Øp x·∫øp exports theo th·ª© t·ª± alphabet
 *    - Lu√¥n th√™m "./package.json" export
 * 
 * 6. UPDATE PACKAGE.JSON
 *    - ƒê·ªçc package.json hi·ªán t·∫°i
 *    - Merge exports m·ªõi v√†o (gi·ªØ nguy√™n c√°c fields kh√°c)
 *    - Write l·∫°i file v·ªõi formatting ƒë·∫πp
 */

import { readdir, readFile, writeFile, access } from "node:fs/promises";
import { join, relative, dirname, basename, extname, resolve, normalize } from "node:path";
import { fileURLToPath } from "node:url";

const DIST_DIR = "dist";
const PACKAGE_JSON = "package.json";

/**
 * Module file structure
 */
interface ModuleFiles {
  js: string | null;
  cjs: string | null;
  dts: string | null;
}

/**
 * Module information
 */
interface Module {
  path: string;
  files: ModuleFiles;
}

/**
 * Export entry structure
 */
interface ExportEntry {
  types: string;
  import?: string;
  require?: string;
}

/**
 * Package.json structure
 */
interface PackageJson {
  name?: string;
  exports?: Record<string, ExportEntry | string>;
  [key: string]: unknown;
}

/**
 * Scan th∆∞ m·ª•c recursively ƒë·ªÉ t√¨m t·∫•t c·∫£ files
 */
async function scanDirectory(dir: string, baseDir: string = dir): Promise<string[]> {
  const entries = await readdir(dir, { withFileTypes: true });
  const files: string[] = [];

  for (const entry of entries) {
    const fullPath = join(dir, entry.name);

    if (entry.isDirectory()) {
      const subFiles = await scanDirectory(fullPath, baseDir);
      files.push(...subFiles);
    } else if (entry.isFile()) {
      const relativePath = normalize(relative(baseDir, fullPath)).replace(/\\/g, "/");
      files.push(relativePath);
    }
  }

  return files;
}

/**
 * Ph√¢n lo·∫°i files theo module name (b·ªè extension)
 */
function groupFilesByModule(files: string[]): Map<string, Module> {
  const modules = new Map<string, Module>();

  for (const file of files) {
    // Handle .d.ts first (special case - double extension)
    let ext: string;
    let modulePath: string;
    
    if (file.endsWith(".d.ts")) {
      ext = ".d.ts";
      modulePath = file.slice(0, -5); // Remove ".d.ts"
    } else {
      ext = extname(file);
      // Ch·ªâ x·ª≠ l√Ω c√°c file c√≥ extension h·ª£p l·ªá
      if (![".js", ".cjs"].includes(ext)) {
        continue;
      }
      modulePath = file.slice(0, -ext.length); // Remove extension
    }

    const name = basename(modulePath);

    // B·ªè qua n·∫øu l√† file trong th∆∞ m·ª•c con kh√¥ng c√≥ t√™n file
    if (!name) {
      continue;
    }

    const key = modulePath;

    if (!modules.has(key)) {
      modules.set(key, {
        path: modulePath,
        files: {
          js: null,
          cjs: null,
          dts: null,
        },
      });
    }

    const module = modules.get(key)!;

    if (ext === ".js") {
      module.files.js = file;
    } else if (ext === ".cjs") {
      module.files.cjs = file;
    } else if (ext === ".d.ts") {
      module.files.dts = file;
    }
  }

  return modules;
}

/**
 * Validate module c√≥ ƒë·ªß files c·∫ßn thi·∫øt
 */
function isValidModule(module: Module): boolean {
  const { files } = module;
  
  // Ph·∫£i c√≥ √≠t nh·∫•t .js v√† .d.ts
  // .cjs l√† optional nh∆∞ng n√™n c√≥ ƒë·ªÉ support CommonJS
  return files.js !== null && files.dts !== null;
}

/**
 * Convert dist path th√†nh export path
 */
function toExportPath(distPath: string): string {
  // dist/index ‚Üí "."
  if (distPath === "index") {
    return ".";
  }
  
  // dist/loaders/cloudinary ‚Üí "./loaders/cloudinary"
  return `./${distPath}`;
}

/**
 * T·∫°o export object cho m·ªôt module
 */
function createExportEntry(module: Module): { exportPath: string; entry: ExportEntry } {
  const { path, files } = module;
  const exportPath = toExportPath(path);
  const distPath = `./dist/${path}`;

  const entry: ExportEntry = {
    types: `${distPath}.d.ts`,
  };

  if (files.js) {
    entry.import = `${distPath}.js`;
  }

  if (files.cjs) {
    entry.require = `${distPath}.cjs`;
  }

  return { exportPath, entry };
}

/**
 * Generate exports t·ª´ th∆∞ m·ª•c dist
 */
async function generateExports(distDir: string): Promise<Record<string, ExportEntry | string>> {
  // 1. Scan th∆∞ m·ª•c dist
  const files = await scanDirectory(distDir);
  
  if (files.length === 0) {
    console.warn("‚ö†Ô∏è  No files found in dist directory");
    return { "./package.json": "./package.json" };
  }
  
  // 2. Ph√¢n lo·∫°i files theo module
  const modules = groupFilesByModule(files);
  
  if (modules.size === 0) {
    console.warn("‚ö†Ô∏è  No valid modules found (need .js and .d.ts files)");
    return { "./package.json": "./package.json" };
  }
  
  // 3. Filter v√† validate modules
  const validModules = Array.from(modules.values()).filter(isValidModule);
  
  if (validModules.length === 0) {
    console.warn("‚ö†Ô∏è  No valid modules after validation");
    return { "./package.json": "./package.json" };
  }
  
  // 4. T·∫°o exports object
  const exports: Record<string, ExportEntry> = {};
  
  for (const module of validModules) {
    const { exportPath, entry } = createExportEntry(module);
    exports[exportPath] = entry;
  }
  
  // 5. S·∫Øp x·∫øp exports (root entry ƒë·∫ßu ti√™n, sau ƒë√≥ alphabet)
  const sortedExports: Record<string, ExportEntry | string> = {};
  const exportKeys = Object.keys(exports).sort((a, b) => {
    // "." lu√¥n ƒë·ª©ng ƒë·∫ßu
    if (a === ".") return -1;
    if (b === ".") return 1;
    return a.localeCompare(b);
  });
  
  for (const key of exportKeys) {
    sortedExports[key] = exports[key];
  }
  
  // 6. Lu√¥n th√™m package.json export
  sortedExports["./package.json"] = "./package.json";
  
  return sortedExports;
}

/**
 * Update package.json v·ªõi exports m·ªõi
 */
async function updatePackageJson(
  packageJsonPath: string,
  newExports: Record<string, ExportEntry | string>
): Promise<PackageJson> {
  const content = await readFile(packageJsonPath, "utf-8");
  const packageJson = JSON.parse(content) as PackageJson;
  
  // Merge exports m·ªõi
  packageJson.exports = newExports;
  
  // Write l·∫°i v·ªõi formatting
  const updated = JSON.stringify(packageJson, null, 2);
  await writeFile(packageJsonPath, updated + "\n", "utf-8");
  
  return packageJson;
}

/**
 * Process a single package
 */
async function processPackage(packageDir: string): Promise<void> {
  const distDir = resolve(packageDir, DIST_DIR);
  const packageJsonPath = resolve(packageDir, PACKAGE_JSON);
  
  // Validate paths
  try {
    await access(packageJsonPath);
    await access(distDir);
  } catch (error) {
    console.warn(`‚ö†Ô∏è  Skipping ${packageDir}: package.json or dist/ not found`);
    return;
  }
  
  try {
    const packageJsonContent = await readFile(packageJsonPath, "utf-8");
    const packageJson = JSON.parse(packageJsonContent) as PackageJson;
    const packageName = packageJson.name || basename(packageDir);
    
    console.log(`\nüì¶ Processing package: ${packageName}`);
    console.log(`üìÅ Package directory: ${packageDir}`);
    console.log("üîç Scanning dist directory...");
    
    const exports = await generateExports(distDir);
    
    console.log(`‚úÖ Found ${Object.keys(exports).length} export entries`);
    console.log("üìù Updating package.json...");
    
    await updatePackageJson(packageJsonPath, exports);
    
    console.log("‚ú® Done! package.json exports updated.");
  } catch (error) {
    const err = error as Error;
    console.error(`‚ùå Error processing ${packageDir}:`, err.message);
    if (err.stack) {
      console.error(err.stack);
    }
    throw error;
  }
}

/**
 * Find all packages with dist/ directory
 */
async function findAllPackages(packagesDir: string): Promise<string[]> {
  const packages: string[] = [];
  
  try {
    const entries = await readdir(packagesDir, { withFileTypes: true });
    
    for (const entry of entries) {
      if (!entry.isDirectory()) {
        continue;
      }
      
      const packagePath = resolve(packagesDir, entry.name);
      const distPath = resolve(packagePath, DIST_DIR);
      const packageJsonPath = resolve(packagePath, PACKAGE_JSON);
      
      try {
        // Check if package has both package.json and dist/
        await access(packageJsonPath);
        await access(distPath);
        packages.push(packagePath);
      } catch {
        // Skip packages without dist/ or package.json
        continue;
      }
    }
  } catch (error) {
    console.error(`‚ùå Error scanning packages directory: ${error}`);
  }
  
  return packages;
}

/**
 * Main function
 */
async function main(): Promise<void> {
  // Get workspace root (parent of scripts directory)
  const scriptPath = fileURLToPath(import.meta.url);
  const scriptsDir = dirname(scriptPath);
  const rootDir = resolve(scriptsDir, "..");
  
  const args = process.argv.slice(2);
  
  try {
    if (args.length > 0) {
      // Process single package
      const packageDir = resolve(rootDir, args[0]);
      await processPackage(packageDir);
    } else {
      // Process all packages
      const packagesDir = resolve(rootDir, "packages");
      console.log("üîç Scanning for packages with dist/ directory...");
      
      const packages = await findAllPackages(packagesDir);
      
      if (packages.length === 0) {
        console.warn("‚ö†Ô∏è  No packages with dist/ directory found");
        return;
      }
      
      console.log(`üì¶ Found ${packages.length} package(s) to process:\n`);
      for (const pkg of packages) {
        console.log(`  - ${basename(pkg)}`);
      }
      
      let successCount = 0;
      let errorCount = 0;
      
      for (const packageDir of packages) {
        try {
          await processPackage(packageDir);
          successCount++;
        } catch {
          errorCount++;
        }
      }
      
      console.log(`\nüìä Summary:`);
      console.log(`  ‚úÖ Success: ${successCount}`);
      if (errorCount > 0) {
        console.log(`  ‚ùå Errors: ${errorCount}`);
      }
    }
  } catch (error) {
    const err = error as Error;
    console.error("‚ùå Error:", err.message);
    if (err.stack) {
      console.error(err.stack);
    }
    process.exit(1);
  }
}

// Run script
main();

